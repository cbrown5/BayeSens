% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/postshrink.R
\name{postshrink}
\alias{postshrink}
\title{Estimate posterior shrink}
\usage{
postshrink(thetaprior, thetapost, thetaMLE)
}
\arguments{
\item{thetaprior}{A \code{numeric} giving the estimate of a parameter
from the prior}

\item{thetapost}{A \code{numeric} giving the estimate of a parameter
from the posterior}

\item{thetaMLE}{A \code{numeric} giving the maximum likelihood estimate
of a parameter}
}
\value{
An estimate of posterior shrinkage.
}
\description{
Estimate posterior shrink
}
\details{
Posterior shrinkage measures the degree to which the posterior
estimate has shrunk towards the maximum likelihood estimate and away from the
prior.

Values close to zero indicate the prior has little influence on the
posterior, whereas values close to 1 indicate the prior has a large
influence on the posterior.

Some care must be taken in selecting parameter estimates to use in the
shrink equation and also in estimating the MLE (which is not always
straightfoward). For complex models the MLE may be estiamted using data
cloning, see \code{\link{dataclone}}.

Shrink values can occaisionally be negative. Negative values occur when
the posterior parameter estimate has moved in the opposite direction from
the prior than the MLE. Negative values can occur if (1) your MLE estimate
is inaccurate, (2) your posterior is multi-model, or (3) your posterior
estimate is constrained by other parameters. If (1) then try other methods
for obtaining an MLE or increase replication if using data cloning.
If (2) or (3) posterior shrink may be inappropriate for your model, because
the posterior shrink cannot be characterised by a simple univariate measure. 

See: Berger JO (1985) Statistical Decision Theory and Bayesian Analysis,
Second Edition, Springer, New York.

Thanks to Ed Boone for suggesting this one.
}
\author{
Christopher J. Brown christo.j.brown@gmail.com
}

